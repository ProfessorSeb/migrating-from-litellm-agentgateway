# =============================================================================
# LiteLLM Proxy Configuration
# =============================================================================
# This config sets up LiteLLM as a proxy to route requests to multiple LLM
# providers (OpenAI, Anthropic) via the OpenAI-compatible API format.
#
# Docs: https://docs.litellm.ai/docs/proxy/configs
# =============================================================================

model_list:
  # -------------------------------------------------------------------------
  # OpenAI Models
  # -------------------------------------------------------------------------
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY

  # -------------------------------------------------------------------------
  # Anthropic Models
  # -------------------------------------------------------------------------
  - model_name: claude-sonnet
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-haiku
    litellm_params:
      model: anthropic/claude-haiku-4-5-20251001
      api_key: os.environ/ANTHROPIC_API_KEY

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  store_model_in_db: true

litellm_settings:
  drop_params: true
  set_verbose: false
